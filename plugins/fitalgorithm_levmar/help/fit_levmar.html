<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head><body>

This implements a Levenberg-Marquardt Least-Squares scheme using the library 
<a href="http://www.ics.forth.gr/%7Elourakis/levmar/">levmar</a>

<p><a href="http://www.ics.forth.gr/%7Elourakis/levmar/">levmar</a> is an
open source implementation of the Levenberg-Marquardt fitting algorithm
which is widely used in different open source projects. </p>
<p>
The next lines will give a short (and basic) description of the
Levenberg-Marquardt method, as it is also described in
<blockquote><b>[PRE92]</b> Press, W. H., Teukolsky, S. A., Vetterling, W. T. und Flannery, B. P.: <b>Numerical Recipes in C.</b>
The Art of Scientific Computing. 2. Auflage, Cambridge University
Press, Cambridge - New York - Port Chester - Melbourne - Sydney,
1992</blockquote></p><p>
We start from a least-squares score function </p><p class="formulaDsp">
<blockquote><img  style="text-align: center;"  alt="\[ \chi^2(\vec{p})=\sum\limits_{i=1}^N\frac{\bigl(y_i-m(\tau_i, \vec{p})\bigr)^2}{\sigma_i^2} \]" src="form_213.png"></blockquote>
</p><p>
 which we want to minimize with respect to the M parameters <img style="vertical-align: middle;"  alt="$ \vec{p}=(p_1,...,p_M)^t $" src="form_210.png">, i.e. we want to solve the minimization problem </p><p  style="vertical-align: middle;" >
<blockquote><img  style="text-align: center;"  alt="\[ \min\limits_{\vec{p}}\chi^2(\vec{p}) \]" src="form_214.png"></blockquote>
</p><p>
 with the N measured data points <img style="vertical-align: middle;"  alt="$ (\tau_i, y_i)_{i=1..N} $" src="form_215.png">.</p><p>
To do so we first note that it should be possible to approximate <img style="vertical-align: middle;"  alt="$ \chi^2 $" src="form_41.png"> by a quadratic form, if the local interval we look at is small enough. In this approximative case we have: </p><p  style="vertical-align: middle;" >
<blockquote><img  style="text-align: center;"  alt="\[ \chi^2(\vec{p})\approx \gamma+\vec{d}\cdot\vec{p}+\frac{1}{2}\vec{p}\cdot\underline{H}\cdot\vec{p} \]" src="form_265.png"></blockquote>
</p><p>
 Here <img style="vertical-align: middle;"  alt="$ \vec{d}=\vec{\nabla}\chi^2(\vec{p}_{opt}) $" src="form_266.png"> is the gradient of the function in the optimum <img style="vertical-align: middle;"  alt="$ \vec{p}_{opt} $" src="form_267.png"> which has to be 0 for an extremum. <img style="vertical-align: middle;"  alt="$ \underline{H}=(H_{i,j})=\frac{\partial^2\chi^2}{\partial p_i\;\partial p_j} $" src="form_268.png"> is the Hessian matrix or the matrix of the second derivatives also evaluated at <img style="vertical-align: middle;"  alt="$ \vec{p}_{opt} $" src="form_267.png">.</p><p>
If this approximation is valid, one may <em>jump to the minimum of this quadratic form in one single leap</em>. Say the current parameter estimation is <img style="vertical-align: middle;"  alt="$ \vec{p}_{cur} $" src="form_261.png">, then the optimal parameter vector is </p><p  style="vertical-align: middle;" >
<blockquote><img  style="text-align: center;"  alt="\[ \vec{p}_{opt}=\vec{p}_{cur}+\underline{H}^{-1}\cdot\bigl[-\vec{\nabla}\chi^2(\vec{p}_{cur})\bigr]. \]" src="form_262.png"></blockquote>
</p><p>
 This result may be optained from the above approximation if you demand <img style="vertical-align: middle;"  alt="$ \vec{\nabla}\chi^2 $" src="form_258.png"> to vanish at <img style="vertical-align: middle;"  alt="$ \vec{p}=\vec{p}_{opt}. $" src="form_269.png"> Note that <img style="vertical-align: middle;"  alt="$ \vec{d} $" src="form_270.png"> and <img style="vertical-align: middle;"  alt="$ \underline{H} $" src="form_271.png"> have to be known constants, so the algorithm has to estimate these to do the jump.</p><p>
If the above approximation is not valid we can not do much more than do a leap in the direction of the <em>steepest descent:</em> </p><p  style="vertical-align: middle;" >
<blockquote><img  style="text-align: center;"  alt="\[ \vec{p}_{nex}=\vec{p}_{cur}-c\cdot\vec{\nabla}\chi^2(\vec{p}_{cur}) \]" src="form_264.png"></blockquote>
</p><p>
 Here c denotes a positive constant which influences the jump size.</p><p>
The Levenberg-Marquardt method is designed to vary smoothly between the
two extremal cases described here. It uses the fact that the form of
the function <img style="vertical-align: middle;"  alt="$ \chi^2(\vec{p}) $" src="form_272.png"> is known to be a quadratic form. So it is easy to estimate the first and second dervative if <img style="vertical-align: middle;"  alt="$ \chi^2(\vec{p}) $" src="form_272.png"> if the user provides the derivatives of the model function <img style="vertical-align: middle;"  alt="$ \bigl(\vec{\nabla}_{\vec{p}}m\bigr)(x,\vec{p}). $" src="form_274.png"></p><p>
This implementation of the Levenberg-Marquardt scheme uses numerical
methods to calculate the gradient, so it is not neccessary to know an
analytic form of the derivatives. Levmar estimates the derivatives with
the central difference scheme which is slower, but mor accurate than
the standard forward/backward schemes. </p>
</body></html>